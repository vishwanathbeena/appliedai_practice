{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_7_SGD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishwanathbeena/appliedai_practice/blob/main/Assignment_7_SGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eiDWcM_MC3H"
      },
      "source": [
        "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfe2NTQtLq11"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk5DSPCLxqT-"
      },
      "source": [
        "<font color='red'> Importing packages</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Et8BKIxnsp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpSk3WQBx7TQ"
      },
      "source": [
        "<font color='red'>Creating custom dataset</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsMp0oWzx6dv"
      },
      "source": [
        "# please don't change random_state\n",
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
        "# make_classification is used to create custom dataset \n",
        "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8W2fg1cyGdX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c7875a-aa2e-49e0-ba2e-6c8579a3dec6"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x99RWCgpqNHw"
      },
      "source": [
        "<font color='red'>Splitting data into train and test </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Kh4dBfVyJMP"
      },
      "source": [
        "#please don't change random state\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gONY1YiDq7jD"
      },
      "source": [
        "# Standardizing the data.\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DR_YMBsyOci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939099d3-f93a-4ae7-d675-b5a70874832b"
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4OHswfqjHR"
      },
      "source": [
        "# <font color='red' size=5>SGD classifier</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HpvTwDHyQQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f94e648-806c-482f-8ea1-f526bb316310"
      },
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYaVyQ2lyXcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd238e0-4dc8-448e-ecd6-538e5a44b39a"
      },
      "source": [
        "clf.fit(X=x_train, y=y_train) # fitting our model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.70, NNZs: 15, Bias: -0.501317, T: 37500, Avg. loss: 0.552526\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.752393, T: 75000, Avg. loss: 0.448021\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 1.26, NNZs: 15, Bias: -0.902742, T: 112500, Avg. loss: 0.415724\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.43, NNZs: 15, Bias: -1.003816, T: 150000, Avg. loss: 0.400895\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.55, NNZs: 15, Bias: -1.076296, T: 187500, Avg. loss: 0.392879\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.65, NNZs: 15, Bias: -1.131077, T: 225000, Avg. loss: 0.388094\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.73, NNZs: 15, Bias: -1.171791, T: 262500, Avg. loss: 0.385077\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.80, NNZs: 15, Bias: -1.203840, T: 300000, Avg. loss: 0.383074\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.86, NNZs: 15, Bias: -1.229563, T: 337500, Avg. loss: 0.381703\n",
            "Total training time: 0.08 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.90, NNZs: 15, Bias: -1.251245, T: 375000, Avg. loss: 0.380763\n",
            "Total training time: 0.09 seconds.\n",
            "-- Epoch 11\n",
            "Norm: 1.94, NNZs: 15, Bias: -1.269044, T: 412500, Avg. loss: 0.380084\n",
            "Total training time: 0.10 seconds.\n",
            "-- Epoch 12\n",
            "Norm: 1.98, NNZs: 15, Bias: -1.282485, T: 450000, Avg. loss: 0.379607\n",
            "Total training time: 0.11 seconds.\n",
            "-- Epoch 13\n",
            "Norm: 2.01, NNZs: 15, Bias: -1.294386, T: 487500, Avg. loss: 0.379251\n",
            "Total training time: 0.12 seconds.\n",
            "-- Epoch 14\n",
            "Norm: 2.03, NNZs: 15, Bias: -1.305805, T: 525000, Avg. loss: 0.378992\n",
            "Total training time: 0.13 seconds.\n",
            "Convergence after 14 epochs took 0.13 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
              "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
              "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
              "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y06fjWP8Fp-N"
      },
      "source": [
        "clf_pred = clf.predict(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDDo78OpF0rp",
        "outputId": "64b6f0a5-4789-4181-8529-b5b17079cdfc"
      },
      "source": [
        "from sklearn.metrics import log_loss\n",
        "loss = log_loss(y_train,clf_pred)\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.80164022473331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAfkVI6GyaRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceebe62e-0059-42c0-c46e-05ced0554f89"
      },
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_\n",
        "#clf.coef_ will return the weights\n",
        "#clf.coef_.shape will return the shape of weights\n",
        "#clf.intercept_ will return the intercept term"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.89007184,  0.63162363, -0.07594145,  0.63107107, -0.38434375,\n",
              "          0.93235243, -0.89573521, -0.07340522,  0.40591417,  0.4199991 ,\n",
              "          0.24722143,  0.05046199, -0.08877987,  0.54081652,  0.06643888]]),\n",
              " (1, 15),\n",
              " array([-1.30580538]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-CcGTKgsMrY"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1_8bdzitDlM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "1.  We will be giving you some functions, please write code in that functions only.\n",
        "\n",
        "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2Y3-FQuJ3z"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
        "\n",
        "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
        "- for each epoch:\n",
        "\n",
        "    - for each batch of data points in train: (keep batch size=1)\n",
        "\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
        "\n",
        "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
        "\n",
        "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
        "\n",
        "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "\n",
        "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
        "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
        "\n",
        "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
        "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
        "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
        "        you can stop the training\n",
        "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR_HgjgS_wKu"
      },
      "source": [
        "<font color='blue'>Initialize weights </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GecwYV9fsKZ9"
      },
      "source": [
        "def initialize_weights(dim):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    #initialize the weights to zeros array of (1,dim) dimensions\n",
        "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    #initialize bias to zero\n",
        "    w = np.zeros(len(dim))\n",
        "    #w = np.zeros((1,len(dim)))\n",
        "    b = 0\n",
        "    return w,b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7I6uWBRsKc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9835b718-a9a2-4295-8087-9e2946c437ca"
      },
      "source": [
        "dim=x_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "print(x_train.shape)\n",
        "print(len(x_train))\n",
        "print('w =',(w))\n",
        "print('b =',str(b))\n",
        "print(w.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37500, 15)\n",
            "37500\n",
            "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "b = 0\n",
            "(15,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MI5SAjP9ofN"
      },
      "source": [
        "<font color='cyan'>Grader function - 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv1llH429wG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c844121b-9374-42e5-da45-87715e3bf7bb"
      },
      "source": [
        "dim=x_train[0] \n",
        "print(dim)\n",
        "w,b = initialize_weights(dim)\n",
        "def grader_weights(w,b):\n",
        "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
        "  return True\n",
        "grader_weights(w,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.39348337 -0.19771903 -0.15037836 -0.21528098 -1.28594363 -0.66049132\n",
            "  0.04140556 -0.22680269 -0.511055   -0.42871073  0.4210912   0.22560347\n",
            " -0.6624427  -0.68888516  0.56015427]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN83oMWy_5rv"
      },
      "source": [
        "<font color='blue'>Compute sigmoid </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPv4NJuxABgs"
      },
      "source": [
        "$sigmoid(z)= 1/(1+exp(-z))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAfmQF47_Sd6"
      },
      "source": [
        "import math\n",
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    sigmoid = (1)/(1 + (np.exp(-z)))\n",
        "    return sigmoid\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YrGDwg3Ae4m"
      },
      "source": [
        "<font color='cyan'>Grader function - 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_JASp_NAfK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d626fe6-1348-4862-8177-cd08fbf17303"
      },
      "source": [
        "def grader_sigmoid(z):\n",
        "  val=sigmoid(z)\n",
        "  assert(val==0.8807970779778823)\n",
        "  return True\n",
        "grader_sigmoid(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7JXbcrBOFF"
      },
      "source": [
        "<font color='blue'> Compute loss </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEiS22zBVYy"
      },
      "source": [
        "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaFDgsp3sKi6"
      },
      "source": [
        "def logloss(y_true,y_pred):\n",
        "    '''In this function, we will compute log loss '''\n",
        "    x=0\n",
        "    for i in range(len(y_true)):\n",
        "      pred_val = y_pred[i]\n",
        "      if pred_val == 0.0 :\n",
        "        pred_val = 0.0000000000000001\n",
        "      if pred_val == 1.0:\n",
        "        pred_val = 0.9999999999999996\n",
        "      x += ( ( y_true[i]*math.log10(pred_val) ) + ( (1-y_true[i])*math.log10(1-pred_val)) )\n",
        "    loss = ((-1/len(y_true))*x)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs1BTXVSClBt"
      },
      "source": [
        "<font color='cyan'>Grader function - 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzttjvBFCuQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1dd1b8-bb76-4fc7-9c16-c98c9ba401b4"
      },
      "source": [
        "def grader_logloss(true,pred):\n",
        "  loss=logloss(true,pred)\n",
        "  assert(loss==0.07644900402910389)\n",
        "  return True\n",
        "true=[1,1,0,1,0]\n",
        "pred=[0.9,0.8,0.1,0.8,0.2]\n",
        "grader_logloss(true,pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQabIadLCBAB"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to  'w' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMxiYKaCQgd"
      },
      "source": [
        "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMVikyuFsKo5"
      },
      "source": [
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    dw = (x * (y-sigmoid(np.dot(w.T , x) + b))) - ((alpha/N) * w)\n",
        "    return dw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUFLNqL_GER9"
      },
      "source": [
        "<font color='cyan'>Grader function - 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI3xD8ctGEnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2b4286-77eb-448b-b7c5-4464c062395c"
      },
      "source": [
        "def grader_dw(x,y,w,b,alpha,N):\n",
        "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
        "  assert(np.sum(grad_dw)==2.613689585)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(x_train)\n",
        "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8g84_GI62n"
      },
      "source": [
        "<font color='blue'>Compute gradient w.r.to 'b' </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvTYZzZJJ_N"
      },
      "source": [
        "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nUf2ft4EZp8"
      },
      "source": [
        " def gradient_db(x,y,w,b):\n",
        "     '''In this function, we will compute gradient w.r.to b '''\n",
        "     db = y - sigmoid(np.dot(w.T,x)+b)\n",
        "     return db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbcBzufVG6qk"
      },
      "source": [
        "<font color='cyan'>Grader function - 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfFDKmscG5qZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3bd6f6-bf74-428d-e041-ce0257c45a61"
      },
      "source": [
        "def grader_db(x,y,w,b):\n",
        "  grad_db=gradient_db(x,y,w,b)\n",
        "  assert(grad_db==-0.5)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w,grad_b=initialize_weights(grad_x)\n",
        "alpha=0.0001\n",
        "N=len(x_train)\n",
        "grader_db(grad_x,grad_y,grad_w,grad_b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rnFebwb_XhV"
      },
      "source": [
        "def gradient_descent(x,y,N,cur_w,cur_b,alpha,ler_rate):\n",
        "  dw = 0\n",
        "  db= 0\n",
        "  for i in range(N):\n",
        "    dw = dw + gradient_dw(x[i],y[i],cur_w,cur_b,alpha,N)\n",
        "    db = db + gradient_db(x[i],y[i],cur_w,cur_b)\n",
        "  cur_w = cur_w + (ler_rate * dw) \n",
        "  cur_b = cur_b + (ler_rate * db)\n",
        "  return cur_w,cur_b\n",
        "\n",
        "\n",
        "def get_loss(x,y,w,b):\n",
        "  pred= []\n",
        "  for i in range(len(x)):\n",
        "    pred.append(sigmoid(np.dot(w.T,x[i])+b))\n",
        "  return logloss(y,pred)\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGqCbb6XLy7H",
        "outputId": "f9dfd371-7711-49a6-f0c1-956503eb549e"
      },
      "source": [
        "w = np.random.rand(15)\n",
        "print(w.shape)\n",
        "print(w)\n",
        "new_w,new_b = initialize_weights(x_train[0])\n",
        "print(new_w.shape)\n",
        "print(new_w)\n",
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15,)\n",
            "[0.90177874 0.68562451 0.34847228 0.5325076  0.02988125 0.91377059\n",
            " 0.74254962 0.80127858 0.61298589 0.29422407 0.39629071 0.39298921\n",
            " 0.36236321 0.32468425 0.53924128]\n",
            "(15,)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "(37500, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCK0jY_EOvyU"
      },
      "source": [
        "<font color='blue'> Implementing logistic regression</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmAdc5ejEZ25"
      },
      "source": [
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
        "    N=len(x_train)   \n",
        "    w,b = initialize_weights(dim)\n",
        "    # w = np.random.rand(len(x_train[0]))\n",
        "    # print('random weights are',w)\n",
        "    # b = 0 \n",
        "    epoch_number_list = []\n",
        "    train_loss_list = []\n",
        "    test_loss_list = []\n",
        "    cur_train_loss = get_loss(X_train,y_train,w,b)\n",
        "    #cur_train_loss = log_loss(y_train,pred(w,b,X_train))\n",
        "    print('Loss with initial weights is',cur_train_loss)\n",
        "    for i in range(epochs): \n",
        "      train_pred = []\n",
        "      test_pred = []\n",
        "      new_w,new_b = gradient_descent(X_train,y_train,N,w,b,alpha,eta0)\n",
        "      new_train_loss = get_loss(X_train,y_train,new_w,new_b)\n",
        "      new_test_loss = get_loss(X_test,y_test,new_w,new_b)\n",
        "      # new_train_loss = log_loss(y_train,pred(new_w,new_b,X_train))\n",
        "      # new_test_loss = log_loss(y_test,pred(new_w,new_b,X_test))\n",
        "      epoch_number_list.append(i)\n",
        "      train_loss_list.append(new_train_loss)\n",
        "      test_loss_list.append(new_test_loss)\n",
        "      w,b = new_w,new_b\n",
        "      print('Epoch {}\\nw= {} || b = {} and loss difference is {}\\n'.format(i,w,b,np.absolute(new_train_loss - cur_train_loss)))\n",
        "      if np.absolute(new_train_loss - cur_train_loss) <= 0.0001:\n",
        "        w,b,cur_train_loss = new_w,new_b,new_train_loss \n",
        "        return w,b,train_loss_list,test_loss_list,epoch_number_list\n",
        "      cur_train_loss = new_train_loss                   \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUquz7LFEZ6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c3f704-f727-414f-b36c-34317722040d"
      },
      "source": [
        "alpha=0.0001\n",
        "eta0=0.0001\n",
        "N=len(x_train)\n",
        "epochs=50\n",
        "w,b,train_loss_list,test_loss_list,epoch_number_list=train(x_train,y_train,x_test,y_test,epochs,alpha,eta0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss with initial weights is 0.3010299956640568\n",
            "Epoch 0\n",
            "w= [-0.50527606  0.27125064  0.29796156  0.31767113  0.00153888  0.6285029\n",
            " -0.52066271 -0.00733669  0.33676899  0.00289615  0.04399698 -0.02998135\n",
            "  0.05843319  0.27567668  0.27109623] || b = -0.7421 and loss difference is 0.10542675823527281\n",
            "\n",
            "Epoch 1\n",
            "w= [-0.50509607  0.35066114  0.01751071  0.37725023 -0.13387113  0.62861534\n",
            " -0.6974739  -0.06470398  0.17507011  0.12398835  0.17691025 -0.02057985\n",
            " -0.02741678  0.34978805  0.06741153] || b = -0.9980372078480024 and loss difference is 0.018074958601333235\n",
            "\n",
            "Epoch 2\n",
            "w= [-0.65421166  0.42561815  0.05913107  0.47884373 -0.13049057  0.68994461\n",
            " -0.68968792 -0.04465511  0.34331045  0.21269373  0.10387078  0.05557964\n",
            " -0.06232669  0.44728238  0.10918778] || b = -1.0638528790155455 and loss difference is 0.005267467766282757\n",
            "\n",
            "Epoch 3\n",
            "w= [-0.67128353  0.48630613 -0.00461999  0.48260573 -0.23291795  0.74908719\n",
            " -0.79888854 -0.0729616   0.27645567  0.23791498  0.21596997  0.0097227\n",
            " -0.04925081  0.43218793  0.06928482] || b = -1.1384711662264955 and loss difference is 0.003093055953957591\n",
            "\n",
            "Epoch 4\n",
            "w= [-0.74737762  0.51306479  0.00352954  0.54184034 -0.23530326  0.78591682\n",
            " -0.78671815 -0.05985316  0.36258694  0.29774948  0.16727806  0.0500364\n",
            " -0.07688087  0.49284727  0.0855546 ] || b = -1.1727511683154699 and loss difference is 0.001802774788475986\n",
            "\n",
            "Epoch 5\n",
            "w= [-0.76718556  0.5487455  -0.02909292  0.54905885 -0.29064859  0.82325921\n",
            " -0.84014718 -0.07353721  0.3377675   0.31555815  0.22316434  0.03153213\n",
            " -0.06876899  0.4848622   0.06973719] || b = -1.2113007862818128 and loss difference is 0.0010837697562323945\n",
            "\n",
            "Epoch 6\n",
            "w= [-0.80831063  0.5674883  -0.03182138  0.57963919 -0.30165373  0.84932958\n",
            " -0.84149345 -0.06827459  0.37677396  0.34945173  0.20795255  0.04802191\n",
            " -0.08072054  0.51299628  0.07501588] || b = -1.233697024097091 and loss difference is 0.0006608023121040252\n",
            "\n",
            "Epoch 7\n",
            "w= [-0.82720823  0.58838647 -0.04859004  0.59011838 -0.33105284  0.87380793\n",
            " -0.86633635 -0.07313041  0.37385799  0.36560251  0.23110798  0.04294895\n",
            " -0.07947739  0.51462963  0.0692446 ] || b = -1.2566352719388751 and loss difference is 0.0004229944454926804\n",
            "\n",
            "Epoch 8\n",
            "w= [-0.85117803  0.60258642 -0.05453066  0.60686226 -0.34400365  0.89276555\n",
            " -0.87316962 -0.07167392  0.39114947  0.38551349  0.23034354  0.04906496\n",
            " -0.08433606  0.52749982  0.0702674 ] || b = -1.2728195617538443 and loss difference is 0.0002823220205975807\n",
            "\n",
            "Epoch 9\n",
            "w= [-0.86677347  0.61599584 -0.06392038  0.6165861  -0.3609998   0.90957208\n",
            " -0.88595911 -0.07318395  0.39511107  0.39866203  0.24030513  0.04863683\n",
            " -0.08524314  0.53187253  0.06816857] || b = -1.2877874664144342 and loss difference is 0.00019475733423260366\n",
            "\n",
            "Epoch 10\n",
            "w= [-0.88218305  0.62647318 -0.06960743  0.62694517 -0.37211742  0.92336852\n",
            " -0.89296999 -0.07293944  0.4038774   0.41150772  0.24324104  0.05109169\n",
            " -0.08754752  0.53868448  0.06798173] || b = -1.2995980496080954 and loss difference is 0.00013729538723206147\n",
            "\n",
            "Epoch 11\n",
            "w= [-0.89408375  0.63570057 -0.07555882  0.6346378  -0.38309693  0.93529535\n",
            " -0.90069839 -0.07341755  0.40861226  0.42148205  0.24840923  0.05175827\n",
            " -0.0887189   0.54282332  0.06708725] || b = -1.3099638652169527 and loss difference is 9.816883246255292e-05\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHgaBipdRrHY",
        "outputId": "21806d5a-d7e4-4f5a-bbf7-6661e7eb41a5"
      },
      "source": [
        "print(train_loss_list)\n",
        "print(test_loss_list)\n",
        "print(len(train_loss_list))\n",
        "print(len(test_loss_list))\n",
        "print(epoch_number_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.195603237428784, 0.17752827882745076, 0.172260811061168, 0.1691677551072104, 0.16736498031873442, 0.16628121056250203, 0.165620408250398, 0.16519741380490532, 0.16491509178430774, 0.16472033445007514, 0.16458303906284308, 0.16448487023038053]\n",
            "[0.1952856649278644, 0.1778700806788202, 0.17260432967516645, 0.16965830143372443, 0.16790949866475524, 0.16690347994241275, 0.16628112780779303, 0.1659065988514157, 0.1656531137364096, 0.165488945991445, 0.16537354779749397, 0.16529580611125164]\n",
            "12\n",
            "12\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Zf_wPARlwY"
      },
      "source": [
        "<font color='red'>Goal of assignment</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qhRvOrQrzl7",
        "outputId": "fdb8db85-13c2-4be7-a73e-7ee0d9250094"
      },
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.89408375  0.63570057 -0.07555882  0.6346378  -0.38309693  0.93529535\n",
            " -0.90069839 -0.07341755  0.40861226  0.42148205  0.24840923  0.05175827\n",
            " -0.0887189   0.54282332  0.06708725]\n",
            "-1.3099638652169527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3eF_VSPSH2z"
      },
      "source": [
        "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx8Rs9rfEZ1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c5ec5a-49a6-4f09-86f2-b33e142827c9"
      },
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "w-clf.coef_, b-clf.intercept_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-4.01191670e-03,  4.07694399e-03,  3.82624461e-04,\n",
              "          3.56672684e-03,  1.24682113e-03,  2.94291613e-03,\n",
              "         -4.96317977e-03, -1.23358079e-05,  2.69809112e-03,\n",
              "          1.48294820e-03,  1.18780392e-03,  1.29628554e-03,\n",
              "          6.09638706e-05,  2.00680051e-03,  6.48363137e-04]]),\n",
              " array([-0.00415848]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230YbSgNSUrQ"
      },
      "source": [
        "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
        "\n",
        "* epoch number on X-axis\n",
        "* loss on Y-axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O6GrRt7UeCJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "d982ec58-ef81-4743-d464-111b4379a2fd"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.lineplot(x=epoch_number_list,y=train_loss_list,label = 'Train Loss vs Epochs')\n",
        "sns.lineplot(x=epoch_number_list,y=test_loss_list,label = 'Test Loss vs Epochs')\n",
        "sns.scatterplot(x=epoch_number_list,y=train_loss_list,label= ' Train Loss')\n",
        "sns.scatterplot(x=epoch_number_list,y=test_loss_list,label= ' Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Log Loss')\n",
        "plt.title('Epoch vs Loss Analysis')\n",
        "plt.plot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.plot>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUVfrA8e87yaQnlCTU0EKRkkYJRaRbUFREUUFA0LWtP2XVXdQtusriquuuWHexrL3QdgFdUGwgoHQMIE0gBAg1CaQTUub8/riTMIQAk5BhUt7P89wnc9u5740yb845954jxhiUUkopd9m8HYBSSqnaRROHUkqpStHEoZRSqlI0cSillKoUTRxKKaUqRROHUkqpStHEoeo8ETEi0sHbcdR2IvKUiHx0gWXMEJEnqism5R2aONRFJSIpInJCRHJdlte8HVd1EpG2zmTl68UYlorIcRHx91YMFTHG3GeM+Yu341AXRhOH8obrjDEhLssD3g6oLhGRtsAAwADXezUYVSdp4lA1hohMEpEfROQ1EckSke0iMsxlfwsR+UxEjonILhG522Wfj4j8QUR2i0iOiKwXkVYuxV8uIjtFJFNEXhcRqeD6LZy1ocYu27qLSLqI2EWkg4h874wtXURmVeEez3UPvUVknYhki8gREXnRuT1ARD4SkQxn/GtFpOk5LnM7sAp4D5hY7vrvOe9/ofP3tFpE2rvsf1lE9jtjWC8iA85yHwtF5MFy2zaJyCixTBeRo85yNotIjMv1pzk/R4jI/5z3dExElouIfifVAvofSdU0fYDdQATwZ+C/Ll/kM4FUoAUwGviriAx17nsEGAtcA4QBdwL5LuVeCyQCccAtwFXlL2yMOQisBG5y2XwbMNcYUwT8BfgKaAREAa9W4f7OdQ8vAy8bY8KA9sBs5/aJQAOgFRAO3AecOMc1bgc+di5XVZBkxgBPO+9jF/CMy761QALQGPgEmCMiARVc431gfOmKiMQDLYGFwJXAQKCTM+5bgIwKyvgt1u8iEmgK/AGrlqRqOE0cyhvmO//KLF3udtl3FHjJGFNkjJkF7ABGOGsP/YHHjDEFxpgk4G2sL0mAu4A/GWN2GMtGY4zrl9VzxphMY8w+YAnWl2NFPsFKQDhrJWOc2wCKgDZAC2cMKypz027cQxHQQUQijDG5xphVLtvDgQ7GmBJjzHpjTPZZrnGZM8bZxpj1WEn4tnKHzTPGrDHGFGMll7LfhTHmI2NMhjGm2BjzD8AfuKSCS30GdBKRjs71CcAsY0yhM95QoDMgxphtxphDFZRRBDQH2jj/ey83OnheraCJQ3nDDcaYhi7LWy77DpT78tiL9dd5C+CYMSan3L6Wzs+tsL4kz+awy+d8IOQsx/0H6CcizbH+anYAy537HgUEWCMiW0TkznNcryLnu4dfYf2Vvt3ZHHWtc/uHwGJgpogcFJG/iYj9LNeYCHxljEl3rn9CueYqzvG7EJHficg2Z3NcJlaNIaL8RYwxBcAsYLyzeWmsM06MMd8BrwGvA0dF5E0RCasg1hewajxfiUiyiDx+lntSNYwmDlXTtCzX/9AaOOhcGotIaLl9B5yf92M171wQY8xxrOaoW7H+Up9ZmsiMMYeNMXcbY1oA9wL/lMo95nvOezDG7DTGjAWaAM8Dc0Uk2PnX+NPGmK7ApVjNbreXKxsRCcRqFhokIodF5DDwMBDvbEo6J2d/xqPOMhoZYxoCWVjJsiLvA+OAYUC+MWZl6Q5jzCvGmJ5AV6xkOKX8ycaYHGPMb40x0Vid+I+49mmpmksTh6ppmgCTnZ3RNwNdgEXGmP3Aj8Czzs7iOKy/0EvfK3gb+IuIdHR2zsaJSHgVY/gE64t5NKeaqRCRm0Ukyrl6HKs93nGOcvydsQY4+wkOnOseRGS8iEQaYxxAprMMh4gMEZFYEfEBsrGaeCq67g1ACdaXdYJz6YJVYzoj0VQgFCgG0gBfEXkSq7+oQs5E4QD+gbO24byPRBHp46wV5QEFFcUrIteK9cCBYCWokrPcl6phNHEob/hcTn+PY57LvtVARyAdq9N2tEtfxVigLdZf7vOAPxtjvnHuexGrM/krrC/XfwOBVYzvM2cMh40xG122JwKrRSTXecxvjDHJ5ygnF6sTu3QZep57GA5scZb/MjDGGHMCaAbMdd7XNuB7XL6oXUwE3jXG7HPWjg4bYw5jNRuNk/O/V7IY+BL4BasJrQCrJncuHwCxnErgYCWbt7CS616sjvEXKji3I/AN1u9pJfBPY8yS81xP1QCifVGqphCRScBdxpjLvB2Lco+I3A7co//N6hetcSilqkREgoD7gTe9HYu6uDRxKKUqTUSuwuoLOYJLP5CqH7SpSimlVKVojUMppVSleG30zospIiLCtG3b1tthKKVUrbJ+/fp0Y0xk+e31InG0bduWdevWeTsMpZSqVURkb0XbtalKKaVUpWjiUEopVSmaOJRSSlVKvejjUKo+KyoqIjU1lYKCAm+HomqogIAAoqKisNvPNujy6TRxKFXHpaamEhoaStu2bZEzJz5U9ZwxhoyMDFJTU2nXrp1b52hT1Vk4HIbktFxW7k4nOS0Xh0NflFS1U0FBAeHh4Zo0VIVEhPDw8ErVSLXGUQGHw/DllsM8MjuJgiIHAXYbL96SwPBuzbDZ9B+fqn00aahzqez/H5o4KpCSkccLX27lpo6++JXkExPVgBe+3ErnZqFER55t4jillKoftKmqAsfzCninzxGO/fIjX+04zk1rxvBOnyNk5mnnolKVlZGRQUJCAgkJCTRr1oyWLVuWrRcWFp7z3HXr1jF58uRKXa9t27akp6ef/0AvmDRpEu3atSu7/0svvbRayx88ePBFednZozUOERmONSGND/C2Mea5cvsHAi8BcViT1sx12fc8MMK5+hdjzCzn9veAQVgzhgFMMsYkVWfcnXzTCF3+CLdIJxr4JJJaGEy75Y8QMXEJFUy/rJQ6h/DwcJKSrH+iTz31FCEhIfzud78r219cXIyvb8VfRb169aJXr14XJc6L5YUXXmD06NHeDuOCeKzG4Zzm8nXgaqypLMeKSNdyh+0DJlFuWGYRGQH0wJr6sg/wu3KT3U8xxiQ4l2pNGgDBRelQdIIetp084DuftY5LoOiEtV0pdcEmTZrEfffdR58+fXj00UdZs2YN/fr1o3v37lx66aXs2LEDgKVLl3LttdcCVtK58847GTx4MNHR0bzyyituXy8lJYWhQ4cSFxfHsGHD2LdvHwBz5swhJiaG+Ph4Bg4cCMCWLVvo3bs3CQkJxMXFsXPnztPKmjFjBlOmnJpC/b333uOBBx4gLy+PESNGEB8fT0xMDLNmzXI7vqeeeooJEybQr18/OnbsyFtvvQVYTzxNmTKFmJgYYmNjTyvz+eefJzY2lvj4eB5//PGy7XPmzKF379506tSJ5cuXu3VPleXJGkdvYFfp1JoiMhMYCWwtPcAYk+LcV36e4a7AMmNMMVAsIpuwptWc7cF4y9hCm4E9kNDCfBpIPh87hkJAoLVdqVrs6c+3sPVgdrWW2bVFGH++rlulz0tNTeXHH3/Ex8eH7Oxsli9fjq+vL9988w1/+MMf+M9//nPGOdu3b2fJkiXk5ORwySWX8Otf/9qtdw8efPBBJk6cyMSJE3nnnXeYPHky8+fPZ+rUqSxevJiWLVuSmWlN8z5jxgx+85vfMG7cOAoLCykpKTmtrJtuuol+/frxwgvWbLizZs3ij3/8I19++SUtWrRg4cKFAGRlZVGRKVOmMG3aNAC6devGxx9/DMCmTZtYtWoVeXl5dO/enREjRrBy5UqSkpLYuHEj6enpJCYmMnDgQJKSkliwYAGrV68mKCiIY8eOlZVfXFzMmjVrWLRoEU8//TTffPPNee+psjzZx9GS0+crTnVuc8dGYLiIBIlIBDAEaOWy/xkR2SQi00XEv6ICROQeEVknIuvS0tIqF3nj9jDqDWx2/9KyYNQb1nalVLW4+eab8fHxAawv2ZtvvpmYmBgefvhhtmzZUuE5I0aMwN/fn4iICJo0acKRI0fcutbKlSu57bbbAJgwYQIrVqwAoH///kyaNIm33nqr7Mu0X79+/PWvf+X5559n7969BAaePnV9ZGQk0dHRrFq1ioyMDLZv307//v2JjY3l66+/5rHHHmP58uU0aNCgwlheeOEFkpKSSEpKKksaACNHjiQwMJCIiAiGDBnCmjVrWLFiBWPHjsXHx4emTZsyaNAg1q5dyzfffMMdd9xBUFAQAI0bNy4r58YbbwSgZ8+epKSkuHVPlVUjn6oyxnwlIonAj1izjK0ESlPk74HDgB/WlJWPAVMrKONN53569epVuZcwbDbofB3cu5wTMy4nuuQQ6VFXEmHTZwlU7VaVmoGnBAcHl31+4oknGDJkCPPmzSMlJYXBgwdXeI6//6m/E318fCguLr6gGGbMmMHq1atZuHAhPXv2ZP369dx222306dOHhQsXcs011/DGG28wdOjQ084bM2YMs2fPpnPnzowaNQoRoVOnTmzYsIFFixbxpz/9iWHDhvHkk0+6HUv5R2Kr+gh16e/I9ffjzj1Vhie/CQ9wei0hyrnNLcaYZ5x9GFcAAvzi3H7IWE4C72I1iVU/mw0iL6Eg6lL62raybl+mRy6jlLJqHC1bWg0S7733XrWXf+mllzJz5kwAPv74YwYMGADA7t276dOnD1OnTiUyMpL9+/eTnJxMdHQ0kydPZuTIkWzatOmM8kaNGsWCBQv49NNPGTNmDAAHDx4kKCiI8ePHM2XKFDZs2FCpGBcsWEBBQQEZGRksXbqUxMREBgwYwKxZsygpKSEtLY1ly5bRu3dvrrjiCt59913y8/MBTmuqqog791QZnqxxrAU6ikg7rIQxBrjNnROdHesNjTEZIhKH9dTVV859zY0xh8RKxzcAP3skeqfQzkNotPdL5m7fwvCY5p68lFL11qOPPsrEiROZNm0aI0aMOP8J5xEXF4fN2UJwyy238Oqrr3LHHXfwwgsvEBkZybvvvgtY/Q07d+7EGMOwYcOIj4/n+eef58MPP8Rut9OsWTP+8Ic/nFF+o0aN6NKlC1u3bqV3b+tv182bNzNlyhRsNht2u51//etfFcbm2scBsGbNmrKYhwwZQnp6Ok888QQtWrRg1KhRrFy5kvj4eESEv/3tbzRr1ozhw4eTlJREr1698PPz45prruGvf/3rWX8fs2fPPu89VYZH5xwXkWuwHrf1Ad4xxjwjIlOBdcaYz5zNUfOARkABcNgY001EAoDSdJ0N3Ff69JSIfAdEYtVCkpz7cs8VR69evUyVn20+shX+1Y/pwQ/x8JSnq1aGUl60bds2unTp4u0w1DlU9JjyxVbR/ycist4Yc8bz0B7t4zDGLAIWldv2pMvntVhNWOXPK8B6sqqiMqveMFcVkZ3J921Iq+wNZBcUERbg3uiRSilVV9XIzvEaxWYjv0Vf+u5dx/q9xxlySRNvR6SUqmOeeuopb4dQKfqYkBvCOg8mStLZvs2j3SlKKVUraOJwg1/7QQCUJC/3ciRKKeV9mjjc4eznaJG5joKiC3vjUimlajtNHO6w2cht1ofespWf9H0OpVQ9p4nDTaGdhxAl6WzTfg6lKuVChlUHa6DDH3/8scJ9pQMM1kQpKSkEBgaW3WtCQgIffPBBtZXvOgDkxaZPVbkpsOMg+AaKdi/DGtVdKeWO8w2rfj5Lly4lJCSk2ueuuBjat29fdu91idY43BXZmTzfhjTJWEtRSfnBfJVSlbF+/XoGDRpEz549ueqqqzh06BAAr7zyCl27diUuLo4xY8aQkpLCjBkzmD59OgkJCWXDhJ/Piy++SExMDDExMbz00ksAZx32/PHHHy+7ZvmE5nA4aNu2bdnIuQAdO3bkyJEjFQ7J7q6QkBAefvhhunXrxrBhwygdiDUpKYm+ffsSFxfHqFGjOH78OAC7du3i8ssvJz4+nh49erB7924AcnNzGT16NJ07d2bcuHGUvtB9rnuqDlrjcJfNRnaT3iQe2MDPB7Lo3rqRtyNSqvK+eBwOb67eMpvFwtXPnf84J2MMDz74IAsWLCAyMrJsWPJ33nmH5557jj179uDv709mZiYNGzbkvvvuq1QtZf369bz77rusXr0aYwx9+vRh0KBBJCcnnzHseUZGBvPmzWP79u2IyGkJAsBmszFy5EjmzZvHHXfcwerVq2nTpg1NmzatcEj28nbv3k1CQkLZ+quvvsqAAQPIy8ujV69eTJ8+nalTp/L000/z2muvcfvtt/Pqq68yaNAgnnzySZ5++mleeuklxo0bx+OPP86oUaMoKCjA4XCwf/9+fvrpJ7Zs2UKLFi3o378/P/zwA126dDnnPVUHrXFUQojzfQ7t51Cq6k6ePMnPP//MFVdcQUJCAtOmTSM1NRWwxmsaN24cH3300VlnBTyfFStWMGrUKIKDgwkJCeHGG29k+fLlFQ573qBBAwICAvjVr37Ff//737Jhyl3deuutZbWTmTNncuuttwIVD8leXmlTVelSOriizWYrK2f8+PGsWLGCrKwsMjMzGTTIagqfOHEiy5YtIycnhwMHDjBq1CgAAgICyuLs3bs3UVFR2Gw2EhISSElJceueLpTWOCoh9JIh8B0U7Pwerhrg7XCUqrxK1Aw8xRhDt27dWLly5Rn7Fi5cyLJly/j888955pln2Ly5+mpHZxv2fM2aNXz77bfMnTuX1157je++++608/r168euXbtIS0tj/vz5/OlPfwIqHpI9PDy8SrFd6BDqcGoYdV9f3/Pe04XSGkdlRHYm16cBEemrcTg8NzikUnWZv78/aWlpZYmjqKiILVu2lDW/DBkyhOeff56srCxyc3MJDQ0lJyfH7fIHDBjA/Pnzyc/PJy8vj3nz5jFgwIAKhz3Pzc0lKyuLa665hunTp7Nx48YzyhMRRo0axSOPPEKXLl3KkkNFQ7K7y+FwMHfuXAA++eQTLrvsMho0aECjRo3K+nE+/PBDBg0aRGhoKFFRUcyfPx+wamylw6lXxJ17ulBa46gMm43MJr3pcfAndhzOpkuLimf4Ukqdnc1mY+7cuUyePJmsrCyKi4t56KGH6NSpE+PHjycrKwtjDJMnT6Zhw4Zcd911jB49mgULFpT1Ebh67733yr5UAVatWsWkSZPKhju/66676N69O4sXLz5j2POcnBxGjhxJQUEBxhhefPHFCmO+9dZbSUxMPG2ukIqGZC+vfB/HnXfeyeTJkwkODmbNmjVMmzaNJk2alDWFvf/++9x3333k5+cTHR1dNvz7hx9+yL333suTTz6J3W5nzpw5Z/39untPF8Kjw6rXFBc0rHo5x5e8RqPv/8h/ByzkxmGXVUuZSnmSDqte84SEhJCbe87ZIC66ygyrrk1VldSw6xAA8n753suRKKWUd2jiqCSJ7EKuTwMaHV1DfaitKaWqX02rbVSWJo7KstnIiEgkwfEze9PzvB2NUkpddJo4qiCw4yCiJJ0tW6v5RSqllKoFNHFUQWTs5QDk7Fjq3UCUUsoLNHFUgTTpQo6tAQ2PrPZ2KEopddFp4qgKEdIiEokp3syhzLO/iKOUOl2fPn1ISEigdevWREZGlg03npKSct5zDx48yOjRoyt1vcGDB1Ndj+KrU/QFwCry7zCIlke/4estm2nev4+3w1GqVli92qqlv/fee6xbt47XXnvttP2lQ2ZUpEWLFmVvWyvv0hpHFTWNHQZAzvYlXo5EqerlcBiS03JZuTud5LRcjw+v89RTTzFhwgT69+/PhAkTSElJYcCAAfTo0YMePXqUTeKUkpJCTEwMYCWeG2+8keHDh9OxY0ceffRRt6937NgxbrjhBuLi4ujbty+bNm0C4Pvvvy+rAXXv3p2cnBwOHTrEwIEDSUhIICYmxu1h3es6j9Y4RGQ48DLgA7xtjHmu3P6BwEtAHDDGGDPXZd/zwAjn6l+MMbOc29sBM4FwYD0wwRhz/mnEqplvs65k2xoQenjVxb60Uh7jcBi+3HKYR2YnUVDkIMBu48VbEhjerRk2W9UG4nPH1q1bWbFiBYGBgeTn5/P1118TEBDAzp07GTt2bIXNTUlJSfz000/4+/tzySWX8OCDD9KqVavzXuvPf/4z3bt3Z/78+Xz33XfcfvvtJCUl8fe//53XX3+d/v37k5ubS0BAAG+++SZXXXUVf/zjHykpKTnnGFH1icdqHCLiA7wOXA10BcaKSNdyh+0DJgGflDt3BNADSAD6AL8TkTDn7ueB6caYDsBx4FeeuodzEuFo4150KdzMsdyTXglBqeqWkpFXljQACoocPDI7iZQMz76zdP311xMYGAhYgx7efffdxMbGcvPNN7N169YKzxk2bFjZEOJdu3Zl7969bl1rxYoVTJgwAYChQ4eSkZFBdnY2/fv355FHHuGVV14hMzMTX19fEhMTeffdd3nqqafYvHkzoaGh1XPDtZwnm6p6A7uMMcnOGsFMYKTrAcaYFGPMJqD8lHpdgWXGmGJjTB6wCRgu1tjDQ4HSmsn7wA0evIdzsrcfSJSk8/PWTd4KQalqdSS7oCxplCoocnA0p8Cj1w0ODi77PH36dJo2bcrGjRtZt27dWeclr2hI8Qvx+OOP8/bbb3PixAn69+/P9u3bGThwIMuWLaNly5ZMmjSpWucMr808mThaAq7jDKc6t7ljI1aiCBKRCGAI0AqreSrTGFP6f8hZyxSRe0RknYisK52Wsbo1T7De58jaqv0cqm5oGhZAgP30r4UAu40moQEXLYasrCyaN2+OzWbjww8/POskSVU1YMAAPv74Y8CazzwiIoKwsDB2795NbGwsjz32GImJiWzfvp29e/fStGlT7r77bu666y42bNhQrbHUVjXyqSpjzFcikgj8CKQBK4FK/d9jjHkTeBOs0XGrPUjAr1k3sm0NCD6k/RyqbmgbHsyLtySc0cfRNjz4/CdXk/vvv5+bbrqJDz74gOHDh59WG6mKESNGYLfbAWtSpjfeeIM777yTuLg4goKCeP/99wF46aWXWLJkCTabjW7dunH11Vczc+ZMXnjhBex2OyEhIVrjcPLYsOoi0g94yhhzlXP99wDGmGcrOPY94H+unePl9n8CfAR8gZVImhljistf42yqc1j18na8OoqQ9E00+P12QgLsHrmGUheissOqOxyGlIw8juYU0CQ0gLbhwR7tGFc1Q00ZVn0t0FFE2omIHzAG+MydE0XER0TCnZ/jsJ66+spYWW4JUPoW0ERgQbVHXgm2dgNoKels1XGrVB1hswnRkSH0jY4gOjJEk4Y6g8cSh7Mf4gFgMbANmG2M2SIiU0XkegARSRSRVOBm4A0R2eI83Q4sF5GtWM1N4136NR4DHhGRXVh9Hv/21D24o2XClQAc21K9c/oqpVRN5dE+DmPMImBRuW1PunxeC0RVcF4B1pNVFZWZjPXEVo0Q1LIbWRJG4IGV3g5FKaUuCn1z/EKJcLBhTzqcSKKg8MIeB1RKqdpAE0d1aGv1c2zfvuX8xyqlVC2niaMatEi4AoCMn7/xciRKKeV5mjiqQYPWsWRKGP7az6HUOV3IsOpgjU+1aNGiCvctXbqUa6+9thqjVWdTI18ArHVESA3rQXTmTxQXl+Dr6+PtiJSqkc43rPr5JCUlsW7dOq655hpPhKfcpDWOauJoexktJJ2dO7WfQ9VyDgek74Q9y62fjvJDyVWv3bt3M3z4cHr27MmAAQPYvn07AHPmzCEmJob4+HgGDhxIYWEhTz75JLNmzSIhIYFZs2a5Vf6nn35KbGwsMTExPPbYYwCUlJQwadIkYmJiiI2NZfr06QC88sordO3albi4OMaMGeOZG64DtMZRTVrEXQEbp3F007d06RLn7XCUqhqHA7Z/DvPuhaITYA+EUW9A5+vA5pm/M++55x5mzJhBx44dWb16Nffffz/fffcdU6dOZfHixbRs2ZLMzEz8/PyYOnVqpWoqBw8e5LHHHmP9+vU0atSIK6+8kvnz59OqVSsOHDjAzz//DEBmZiYAzz33HHv27MHf379smzqT1jiqSUR0PJmEYd//g7dDUarqju0+lTTA+jnvXmu7B+Tm5vLjjz9y8803k5CQwL333suhQ4cA6N+/P5MmTeKtt96q8kCHa9euZfDgwURGRuLr68u4ceNYtmwZ0dHRJCcn8+CDD/Lll18SFmbN2hAXF8e4ceP46KOPzjoTodLEUX1E2BvWg3a5P+Eo8WzVXimPyTl8KmmUKjoBuYc9cjmHw0HDhg1JSkoqW7Zt2wbAjBkzmDZtGvv376dnz55kZGRU23UbNWrExo0bGTx4MDNmzOCuu+4CYOHChfzf//0fGzZsIDEx8YKHaq+rNHFUo5LW/WlOOinJ27wdilJVE9rMap5yZQ+EkGYeuVxYWBjt2rVjzpw5ABhj2LhxI2D1ffTp04epU6cSGRnJ/v37CQ0NJScnx+3ye/fuzffff096ejolJSV8+umnDBo0iPT0dBwOBzfddBPTpk1jw4YNOBwO9u/fz5AhQ3j++efJysoiNzfXI/dd22niqEbN4qz5OQ5v1Pc5VC3VuL3Vp1GaPEr7OBq399glP/74Y/79738THx9Pt27dWLDAGrd0ypQpZZ3al156KfHx8QwZMoStW7eetXP822+/JSoqqmxJSUnhueeeY8iQIcTHx9OzZ09GjhzJgQMHGDx4MAkJCYwfP55nn32WkpISxo8fT2xsLN27d2fy5Mk0bNjQY/ddm3lsWPWaxJPDqrsyDgeZU9vwS1g/+jwy2+PXU8odlR1WHYfD6tPIPWzVNBq391jHuKo5KjOsuvb+VCOx2dgT0p3W2esxDgei/9hUbWSzQURHa1GqAvrNVs2KWl1Kc9I5tPcXb4eilFIeoYmjmkXGDgPgQNLXXo5EqVPqQ5O0qrrK/v+hiaOatb2kJ8cIRfYu93YoSgEQEBBARkaGJg9VIWMMGRkZBAQEuH2O9nFUM5uPjeSg7kRlbQBjQHTaTeVdUVFRpKamkpaW5u1QVA0VEBBAVNQZc+qdlSYODyiI6kezX5aRnvoLEa0u8XY4qp6z2+20a9fO22GoOkSbqjwgIsZ6nyP1J+3nUErVPZo4PKB91/UdSfAAACAASURBVJ5kmDBMivZzKKXqHk0cHmD39WFXUAItj6+z+jmUUqoO0cThIfkt+tHEpJN9aKe3Q1FKqWrl0cQhIsNFZIeI7BKRxyvYP1BENohIsYiMLrfvbyKyRUS2icgrItbjSSKy1FlmknNp4sl7qKrG3YYCkLpB+zmUUnWLxxKHiPgArwNXA12BsSLStdxh+4BJwCflzr0U6A/EATFAIjDI5ZBxxpgE53LUM3dwYS6J6UWGCaNkj/ZzKKXqFk/WOHoDu4wxycaYQmAmMNL1AGNMijFmE1B+AgsDBAB+gD9gB454MNZqF+Dny46AeJppP4dSqo7xZOJoCex3WU91bjsvY8xKYAlwyLksNsa4TnLxrrOZ6onSJqyaKLd5XyIdaZw46pnZ05RSyhtqZOe4iHQAugBRWMlmqIgMcO4eZ4yJBQY4lwlnKeMeEVknIuu89cZsw65DAH2fQylVt3gycRwAWrmsRzm3uWMUsMoYk2uMyQW+APoBGGMOOH/mYPWN9K6oAGPMm8aYXsaYXpGRkVW8hQvTJTaRdBNG0e5lXrm+Ukp5gicTx1qgo4i0ExE/YAzwmZvn7gMGiYiviNixOsa3OdcjAJzbrwV+9kDs1SI00I9t/nE0ObZW+zmUUnWGxxKHMaYYeABYDGwDZhtjtojIVBG5HkBEEkUkFbgZeENEtjhPnwvsBjYDG4GNxpjPsTrKF4vIJiAJqwbzlqfuoTrkNO1LREkaJ9OTvR2KUkpVC48OcmiMWQQsKrftSZfPa7GasMqfVwLcW8H2PKBn9UfqOaFdBsP+v3Mo6WvaXuG5eZuVUupiqZGd43VJV2c/x8ld2s+hlKobNHF4WHhoAFvssUSkr9F+DqVUnaCJ4yLIbNqH8JI0So6leDsUpZS6YJo4LoKQToMBOLRR3+dQStV+mjgugi5xVj9HwS/fezsUpZS6YJo4LoIWjYLY5BtDY+3nUErVAZVKHCLSSETiPBVMXXYsojeNi49ijqd4OxSllLog500czvkvwkSkMbABeEtEXvR8aHVLkLOf4+jmb70biFJKXSB3ahwNjDHZwI3AB8aYPsDlng2r7ukc24t0E0b+L0u9HYpSSl0QdxKHr4g0B24B/ufheOqsdpEh/GTrRsMjq7WfQylVq7mTOKZijTe1yxizVkSiAZ1Iu5JEhIyI3jQqPgraz6GUqsXOmziMMXOMMXHGmPud68nGmJs8H1rd499hIADHtn7n5UiUUqrq3Okc/5uzc9wuIt+KSJqIjL8YwdU1l8RY73Pkbl/q7VCUUqrK3GmqutLZOX4tkAJ0AKZ4Mqi66pLmYayXroQdWaX9HEqpWsutznHnzxHAHGNMlgfjqdN8bMLRxok0LNJ+DqVU7eVO4vifiGzHmgfjWxGJBAo8G1bd5ddhEAA5O5Z6NxCllKoidzrHHwcuBXoZY4qAPGCkpwOrqzp07Um6CSN72xJvh6KUUlXiTue4HRgPzBKRucCvgAxPB1ZXxUY1ZK3pSsgh7edQStVO7jRV/QurmeqfzqWHc5uqAj9fG4ca9aJB0RHt51BK1UruJI5EY8xEY8x3zuUOINHTgdVlPtEDADixU4dZV0rVPu4kjhIRaV+64nxzvMRzIdV9HZ39HFnaz6GUqoV8z38IU4AlIpIMCNAGuMOjUdVx3ds0ZomjC/0PrrT6OUS8HZJSSrntvInDGPOtiHQELnFu2oH1MqCqokA/H1Ib9KRB7mqrn6NxO2+HpJRSbnNrIidjzEljzCbnchKY7s55IjJcRHaIyC4RebyC/QNFZIOIFIvI6HL7/iYiW0Rkm4i8ImL9WS4iPUVks7PMsu21jrOfo3D3Mi8HopRSlVPVqWPP+2UtIj7A68DVQFdgrIh0LXfYPmAS8Em5cy8F+gNxQAxWZ/wg5+5/AXcDHZ3L8Creg1d16NKDNBNG5jYd8FApVbtUNXG48wJCb6yh2JONMYXATMq9OGiMSTHGbAIcFZQfAPgB/oAdOOKcFyTMGLPKGGOAD4AbqngPXtWzbTirHV0JPLBS3+dQStUqZ+3jEJHNVJwgBGjqRtktgf0u66lAH3eCMsasFJElwCHn9V4zxmwTkV7OclzLbFlRGSJyD3APQOvWrd257EXVINBOSmgPrs1fpf0cSqla5Vyd417rABeRDkAXIMq56WsRGQCccLcMY8ybwJsAvXr1qpl/0re5DLb9k+I9y/HVxKGUqiXO2lRljNl7rsWNsg8ArVzWo5zb3DEKWGWMyTXG5AJfAP2c50e5HFeZMmuc6C7dSTNhZG/V9zmUUrVHVfs43LEW6Cgi7UTEDxgDfObmufuAQSLi6xwraxCwzRhzCMgWkb7Op6luBxZ4IviLIbGd1c/hl/qD9nMopWoNjyUOY0wx8ADWfOXbgNnGmC0iMlVErgcQkUQRSQVuBt4QkS3O0+cCu4HNwEZgozHmc+e++4G3gV3OY77w1D14WmSoP7uCEgg5eQSO7/F2OEop5RZ33hyvMmPMImBRuW1Punxey+lNT6XbS4B7z1LmOqxHdOuEktb9YecMHHuWY2sc7e1wlFLqvNwZVn2ziGwqtywXkekiEn4xgqzL2nW2+jlydB5ypVQt4U6N4wusQQ1LX9IbAwQBh4H3gOs8Elk9UdrPMWTfDzpulVKqVnAncVxujOnhsr5ZRDYYY3qIyHhPBVZfRDUKZKZ/HNeeXGX1c2hzlVKqhnOnc9xHRHqXrohIIuDjXC32SFT1iIhQ3Ko/AGbPci9Ho5RS5+dO4rgL+LeI7BGRFODfwF0iEgw868ng6ovWlySQZsLI+0UndlJK1XzuDKu+FogVkQbO9SyX3bM9FVh90ifa6ucYmrIMkpdBWHNo3B5snnzNRimlqsadp6oaiMiLwLfAtyLyj9IkoqpH+/AgNtm6EHQyDT64Dt4YANs/B0f5sR+VUsr73PmT9h0gB7jFuWQD73oyqPpGjidzssTlzfGiEzDvXji223tBKaXUWbiTONobY/7sHB492RjzNKCP/lQjR85hWnOIFSXdTo08UnQCR85hr8allFIVcSdxnBCRy0pXRKQ/lRilVp1fnj2CPn4pPFA0mTwCrI2+/uTZI7wbmFJKVcCdxHEf8LqIpDifqnqNswwHoqrml+JIAgY9RIQth4mFj+FAOBnQhN0ngr0dmlJKneG8icMYs9EYE481jWucMaY7MNTjkdUjjYIDuHtNU0b3jma7Tyd+a5uCPTeVDqse1w5ypVSN4/bznsaYbGNMtnP1EQ/FUy+1DQ9myvCuvLS+kLxiYV5+Au8G3UHI7oWw7G/eDk8ppU5T1dFxdUClamSzCcO7NaPz5AEczSngh10Z/OU7Q2LUEeKWPguRl0C3Ud4OUymlgKonDp11qJrZbEJ0ZAjRkSH0aRdORl4ho1ffwsrmBwif92to1A5aJHg7TKWUOntTlYjkiEh2BUsO0OIixljviAhPX9+NHtFNuTbtPgr9G8HM2yDniLdDU0qpc845HmqMCatgCTXGeHQCKAV2Hxv/HNcT37CmTCp4BEf+MZg1DooKvB2aUqqe08GQarDGwX78e2IiG4ta8WzAw5C6Fj7/jc5PrpTyKk0cNVynpqG8MrY7b2fE8HnjO2DTTPjhZW+HpZSqxzRx1ALDujTlseGdefDg5eyIuAK+eQp2fOHtsJRS9ZQmjlri3oHR3Ng9ipGpt5HVsCv85y44stXbYSml6iFNHLWEiPDXG2Pp0rop12c8QJFvEHw6BvIyvB2aUqqe0cRRiwTYfXhjQk8Kg5pyX9FvMTmHYfbtUFzo7dCUUvWIRxOHiAwXkR0isktEHq9g/0AR2SAixSIy2mX7EBFJclkKROQG5773nNPYlu6rV2/FNQkN4K3be/FDQRteDp4Me1fAot/pk1ZKqYvGY4lDRHyA14Grga7AWBHpWu6wfcAk4BPXjcaYJcaYBGNMAtaAivnAVy6HTCndb4xJ8tQ91FQxLRvwj5sTeOlod74JHwcb3oc1b3o7LKVUPeHJGkdvYJdz8qdCYCYw0vUAY0yKMWYTcK4hYEcDXxhj8j0Xau0zIq45D13ekbsPXE1KxGD48vew+ztvh6WUqgc8mThaAvtd1lOd2yprDPBpuW3PiMgmEZkuIv4VnSQi94jIOhFZl5aWVoXL1nyTh3bk6tgWXHtgArlhHWDOJEjf5e2wlFJ1XI3uHBeR5kAssNhl8++BzkAi0Bh4rKJzjTFvGmN6GWN6RUZGejxWb7DZhL/fHE+b5k25MfNBivGBT2+FE8e9HZpSqg7zZOI4ALRyWY9ybquMW4B5xpii0g3GmEPGchJ4F6tJrN4K8vPlrdt7cczenIfNbzHH98LcO6Gk2NuhKaXqKE8mjrVARxFpJyJ+WE1On1WyjLGUa6Zy1kIQEQFuAH6uhlhrtRYNA3nz9p4szmvPm6H/Z/V1fP2Et8NSStVRHkscxphi4AGsZqZtwGxjzBYRmSoi1wOISKKIpAI3A2+IyJbS80WkLVaN5ftyRX8sIpuBzUAEMM1T91Cb9GjdiOdujOXZI735IfIWWPVPWP++t8NSStVBYurB8/+9evUy69at83YYF8WzX2zj7e93sqzlv2h5fC3cvgDa9vd2WEqpWkhE1htjepXfXqM7x1XlPXpVZwZ3bs6IQ3eSH9IKZk+A4yneDkspVYdo4qhjfGzCS2MSaBLZhDHZv6GkpBg+HQsnc7wdmlKqjtDEUQeFBth5+/ZE9tta8HvbI5i0HfDfe8BxrvcslVLKPZo46qjW4UH8c1xP/pvViY8a3gc7FsF3f/F2WEqpOkATRx3Wr304U0fG8MShS9kQORJWvAibZns7LKVULaeJo467rU9rJvZry637b+Jo416w4AFIrR9PmCmlPEMTRz3wxLVd6dOhGdceuZuTgU1g5m2QsgL2LIf0ndr3oZSqFE0c9YCvj43Xb+tBcKNmTMh/BMeJLHj/Wmt5YwBs/1yTh1LKbZo46okGQXbeur0X20qa83TBrRiH88XPohMw7144ttu7ASqlag1NHPVIhyYhvDo0gA9LruA/JQNO7Sg6AbmHvReYUqpW0cRRzwzsGsUf/Wfxu+Jf81lxv7Ltjh2LwVHixciUUrWFJo56Zr80Y+iwa7jVvozJxQ/yl5KJZEckYFv5KrwzXCeCUkqdlyaOeuZg1knG/RBJz/5XcV2bEt4puoruB6fwQ9xfIX0HzLgMVs3QznKl1Flp4qhnmoYFcCy/mEeXnuDzvT4YoMQh3L6uHe8mzMK0HQBfPgYfXK+DIyqlKqSJo55pGx7Mi7ckEGC3/tMH2G38fXQcV3drxtNLj3Fr7sMcG/YPOJgE/+oP696BejD0vlLKfTofRz3kcBhSMvI4mlNAk9AA2oYHIwLzfjrAkwu2IAL/uLIRV+6cBnu+h/ZD4fpXoUGUt0NXSl1EZ5uPQxOHOs2+jHwemvUTG/ZlcmNCc55pvZbAJU+BzQ7Dn4WE20DE22EqpS4CnchJuaV1eBCz7+3HQ5d3ZMGmw1yxvCObr1sETbvBgvutuT1yjng7TKWUF2niUGfw9bHx0OWdmH1vP0Rg5KcHmR71IiVXPAPJS+CffWDzXO37UKqe0sShzqpnm0YsmjyAUd2jePm7ZG5K6s6BWxdD4/bwn1/BnImQl+7tMJVSF5kmDnVOoQF2/nFLPK+O7U5yWi5XfniYufFvY4b9GbYvgn/2hW2feztMpdRFpIlDueW6+BZ88dBAYlo24Hf/3coD+waTPfEbCG0Os8bDf+6GE8e9HaZS6iLQxKHc1rJhIJ/c3ZdHh1/C4i2HueqTDFYOmw2DHoct/4XX+8IvX3k7TKWUh3k0cYjIcBHZISK7ROTxCvYPFJENIlIsIqNdtg8RkSSXpUBEbnDuayciq51lzhIRP0/egzqdj024f3AH5t3fn0C7D7e9s4FnC26g6I5vILARfHKzNctgQba3Q1VKeYjHEoeI+ACvA1cDXYGxItK13GH7gEnAJ64bjTFLjDEJxpgEYCiQD5T+Kfs8MN0Y0wE4DvzKU/egzi42qgH/m3wZYxJb88b3yYyan8uuGxfCZQ9D0sfwr0sheam3w1RKeYAnaxy9gV3GmGRjTCEwExjpeoAxJsUYswk414h6o4EvjDH5IiJYiWSuc9/7wA3VH7pyR5CfL8/eGMubE3py4PgJrv3nGj4KuQNz52Lw9YcPRsLC31q1j/SdOlWtUnWErwfLbgnsd1lPBfpUoZwxwIvOz+FApjGm2KXMlhWdJCL3APcAtG7dugqXVe66slsz4ls15HdzNvKn+T+ztEsTnh//DeGr/war/gVbP4OCTCgpBHsgjHoDOl8HNu1iU6o2qtH/ckWkORALLK7sucaYN40xvYwxvSIjI6s/OHWapmEBvH9Hb564tivLfknnqtfXs7Tdw1aSyEuzkgboVLVK1QGeTBwHgFYu61HObZVxCzDPGFPkXM8AGopIaU2pKmUqD7HZhF9d1o4FD/SncbCdSe+u5anNjSkwPqcfWHQCfvoICvO9E6hS6oJ4MnGsBTo6n4Lyw2py+qySZYwFPi1dMdaIjEuw+j0AJgILqiFWVY26NA/jswcuY9KlbXnv50JGFv2V7Q7XvyEEfngJXuwMix6Fo9u8FqtSqvI8OjquiFwDvAT4AO8YY54RkanAOmPMZyKSCMwDGgEFwGFjTDfnuW2BH4BWxhiHS5nRWB3tjYGfgPHGmJPnikNHx/WeWWv28tzCTeSdLOEB3/mM919B9qCnCWgQSbOds2DbZ1YzVqs+0PMO6HaD1Q+ilPI6HVZdE4dXrNydzkMzNxDp7+Dn9BJ8bWD3sfGHazozvm9bJP8YbPwE1r8HGbsgoCHEj4Wek6BJZ2+Hr1S9polDE4dXJKflcs0ryykoOvMR3G4twpjQtw3XJ7QgyO4DKcth3bvW2FeOImjdz6qFdB0J9gAvRK9U/aaJQxOHVzgchi+3HOaR2UkUFDkIsNv466hY8k4W89Gqfew4kkNogC+je0Yxvm8b2keGQG7aqVrIsWTrjfT426xaSGQnb9+SUvWGJg5NHF5T0VS1NptgjGHd3uN8uHIvX/x8iKISQ/8O4Uzo24bLuzTFV4CUZVYtZPv/wFEMbfo7ayHXWy8ZKqU8RhOHJo4aLS3nJLPX7efjVXs5mFVAs7AAxvZuzdjerWgSFgC5R62hTNa/B8dTILCxNY1tzzsgooO3w1eqTtLEoYmjVihxGL7bfpQPV+1l2S9p+NqEq7o1Y3zfNvSNbowYA3uWWrWQHYusWkjbAVYzVpfrrFqIw2G9YJhzGEKbWRNP6VvqSlWaJg5NHLVOSnoeH6/ey+x1qWSdKKJDkxAm9G3DqB4tCQuwW3OfJ31k1UIy90FQuNUX0rA1fPOk9aKhDnGiVJVp4tDEUWsVFJXw+caDfLR6Hxv3ZxLk58MN3Vsyvk8burYIs2oYyd85ayFfgCk5vQDfALhvBUR09M4NKFVLaeLQxFEnbErN5KNVe1mQdJCTxQ56tWnEhH5tGB7TDH9fH9iyAObcfuaJzeOg43Bo3ReiEiEg7OIHr1Qto4lDE0edkplfyNz1qXy0ai8pGfmEB/txS2IrbuvooNXMoVYzVSmbD4R3sIZ0Nw4QGzTpBq37QKu+1s8GrUDEezekVA2kiUMTR53kcBh+2J3Ohyv38s22IxhgYPMSJh1/hQGO9fj6+ZN3zesExt2ArTgfUtfCvtWwfxWkroPCXKug0BZWbaR1X2v4k6Yx4OPJWQeUqvk0cWjiqPMOZp7gn0t38enqfZQYCPAxtG3ow5ETNqbdEMuV3Zph93HpIC8phqNbTiWSfashO9Xa5xcCLXueSiTavKXqIU0cmjjqhZW70xn71uoK9wX7+dCzbWP6Rjemb3Q4sS0bnJ5IALJSYd8q2L8a9q2EI1tONW817eZs2nImk4at9NFfVaedLXFoXVzVKU3DAgiw204bG8vfV3hseBf2pOexKjmDv325A4AgPx96tmlE3+hw+kaHExfVAHuDKIgdbS0AJ3NOb97a+CmsfcvaF9bC6hs5sMEaW8s3AG58Ux/9VXWe1jhUnVLR2Fgv3pLA8G7NsNmszu/03JOs2XOMVckZrE4+xo4jOQAE2n3o1bY0kTQmtmVD/HzLJQDX5q1dX8POr4Fy/4aaJ1h9JI3bQXh7aBxtLf6hF+E3oFT10aYqTRz1xtnGxjqbDNdEsucY2w9biSTAbqNXG6tpq090OPFR5RLJnuXw/rVnFtg0BvIzIOfQ6duDmzgTSXtNKqpW0MShiUO56VheIWv2ZLAq2UomromkZ5tG9GlnNW3FB6bh/+9Bpz/6aw+Ee5dbLxsW5sGxPVYfSMZua6Tf0qWqSUX7VNRFpIlDE4eqouN5hazec4zVzmSy/XA2xoC/r434xkX0z/ycRPMzHf0yCBzxLEHxN2Dz8Tl3oVVKKtFQfPLUrIm+/nD9axAzWpOH8ghNHJo4VDXJzC9kzZ5jLN5ymM83HqSoxJT1ctgEOjUNpWvzMKIjg4mODKFdRDDtIoIJsJ8nmZQqzDuVRFyTSvovkJd25vH2QCu5BEc6lwiXz+XWg8Ir936K1nDqNX2qSqlq0jDIjyu7NSM0wJf/bDhw2j6HAV8fYWVyBv/96dQ+EWjRIJDoyGDaO5NJaWJpHhZweh+MXzA0i7UWV2frU+l0Ffj4W0klOxUOJVmfHcUVRC/WxFgVJplyCScoHPZ8D/PvuzgDRmqSqjU0cShVRRU9+htgt/HKmO5ER4aQX1hMcloeyel57EnLIzk9l+S0POas209eYclp57SLCLESSWlCca6HBthPXTC0mfXlXb5PZcifzhzA0RgoyIS8dCuJlC3pp38+ssX6XJB5/hsuOgFzJkGHyyGspfVCpH8YBDRw/gw7/ad/qPXTnRqOwwHbP4d59+qoxrWANlUpVUXuPPpbEWMMR3NOsjvNSiTJaXnsSc8lOT2P/cfycbj8k4wM9S9LJu3Cg2iZu5muG/5MVHEqdj+/U8OpnK9P5XyKC60nwVyTyv7VsO7fZx4b2hxKiuBkttXXcj724DOTSvmfxSfhx5etckv5+sOYmdCkizXnvD0IfPyqb0yxi13DqYU1Ku3j0MShPKCyj/6ez8niEvZl5LPbpYayJz2P5LRcjuef+lIVDMF24aRDiI9qSJvwYJqE+dMk1J8moQE0CfMnMsSfJmH+BPlVsWEhfSe8MeDsT40BFBVYCaQgG05mWS9MFmS7bHPZV+H2HCg+UfH1KyI28A204rAHORNKYMXb7EHWS5n2IOe6yzE+/nB4I/zw8qkHDS6fCp2GW+f7+FmLrz/YfC88WV3sGlU1JSmvJA4RGQ68DPgAbxtjniu3fyDwEhAHjDHGzHXZ1xp4G2iF9YbVNcaYFBF5DxgEZDkPnWSMSTpXHJo4VF3w1ZZD3PPhhjO2R0cGc6KwhLSckxQ7zvz3HOLvS5NQfyJD/WkSFnDqs0uSaRLqT4NAO+LyBekoKeHEpvkEL/q/si+7aqvhuCouhEMb4f0RVs2jlI8fDPmjVSspKoCifCuO4tLPrttOWD9PW/KtY4sLLjBAsRKIazIp+2m3ktBp+/1ctjn3F+Vbow649jvZ7HDZw9YIBDZf61ib7zk+262Rnl3XfXxd9vk6mwVtsPMrWHC/de8XkKQueue4iPgArwNXAKnAWhH5zBiz1eWwfcAk4HcVFPEB8Iwx5msRCQEcLvumuCYZpeqDDk1CK+xTefv2XkRHhuBwGI7nF3I056S1ZBdwNOckac7laE4Bm1IzOZp9khNFJWeU7+drIzLkVFIJsPuw7JcQrmjzIS3s+RT6BrPgS8Pfw44T07IBof6+pyWaKvP1g5Y9MaPeRFw64s0NM5Au11/4X+QOhzOxuCSavT/C/35z5rH9fwMN21i1kOKTVtNZyUnn50Ln9kKXbaX7C62Rlk/b7zy+5KR17fIPKziKYNnfLuze3FF0wqrp3Nu12iYz82TneG9glzEmGUBEZgIjgbLEYYxJce5zTQqISFfA1xjztfO4XA/GqVSt0DY8mBdvSTijT6VteDAANpsQHuJPeIg/XZqfvRxjDLkni53J5FSSKV1PyzlJSkYeBzMLyD1ZzJztYH1VWLWB25yDSNoEwgLthAXYaRBoJyzQlwaBzs8Bdmufc93a5us8zlp3HWDSgbDU1pfsPjMJN5lkSEPCbJ0ZjHDBDTk2m/Wkml8wEG5tE6n4QYPuEzwzU2RFzX6+AXD7Z87BMoutJOQosRKK6+cK9xWfWlzXS4ogY6c1nbKrohOQe7hWJI6WwH6X9VSgj5vndgIyReS/QDvgG+BxY8rmBH1GRJ4EvnVuP3mWcpSqM2w2YXi3ZnSePOCC+lREhNAAO6EBdqIjQ856XHJaLle/vIyTxaeav+w+wkPDOuLn60PWiSKyC4rIOmEt2SeKOJxVQHZBMVkniigsdpy1bLAGmSxNOn6+wpaD2c4HA+xAHr62Ddw7KJrWjYMI9PMl2M+HQD8fgv18CfLzIcjflyC7tc3f11ap2o+jUTQnrnn9zGa4RtEXnqgq0ri9VYMqX6OKSqz+Po70nbBp1plJMaRZtV2ipj6O6wsMALpjNWfNwmrS+jfwe+Aw4Ae8CTwGTC1fgIjcA9wD0Lp164sRs1IeZ7MJ0ZEh5/zCry5tw4OZfmv3Sj81VqqgqITs0qRyWoIpLks0pdtSj5/+NBlAscPw+pLdbsXqYxOC7D4E+fv8f3v3HiPVWYdx/PvMBZZLClQoUqiFKGooijXYUBuNoU2sV0iMtvWSakyMxlK8W/UP4+UP0xijaKPBFiSKNBZbJU2VNmC0SU0tN1subWwQC3QRSKUXFnZ3Zn7+cc7CQHcLZ/fMHnb2+SSTeedldvf3spt99n3POe9hfF+wjGlu94VNmfHVCid6a9yzZSLvvvzXTCt3cbw0gfv/1OBbpUPMmTqRjmqJsZUkkMZWyoytlhhTLg36xIeWzqjONlBImZHkLgAABytJREFUXfza3L5EK4PjIMmB7T6z0r7zcQDY0bTM9QdgEXBXRPTtx9AtaTX9Hx8hIlaSBAsLFy5s/1PHzHI21BlOR7VMR7XMJRd1nPO9e4+8xHtXPPyy7fDv/szVXHJRB13dNbp66hzvqXGip05XT52unlr6nLSPd9c50fSe4z01jnX18Oyxpvf01M+YCf12NzQvwy1b94rn2TCmXErCpJqGyhkB09TfFDhjKyVO9NS5Z+t+6g04NaMqb+NL172emVPGUS2XqJREtZIEVLVcolLWqXa1rPQ5bafvq5REuaQzT2oYhpBqZXA8BsyVNIckMG4EPprhYydLmhYRR4DFwBYASTMiolPJ/9RSYGf+pZsZDN8MZ6DjNwtmTR7S6c39qdUb7O58gQ//4pEzluHGlMX3ls5nyvgxnKw16O6t011rpI863b1N7Vojfd30nnSGdeb7k+cTvfU0NJrrCG7f+NSQxyNBtZwGSVmUJJ473nd9TRJSHdXtPHDrO3L7PrYsOCKiJukWYCPJ6birImKXpO8CWyJig6S3AfcBU4APSPpORFwREXVJXwE2pQGxFUjvnsNaSdMAATuAz7ZqDGY2PPI6fnM+KuUS8y+dNKRluKz6O140tiJWf/IqXj2pg9560Ftv0FNvUGtq99Ya1Brp61qD3npQa5xu99Yb6eN0+8D/utj85Jl7mp3sbXD4xZO5BYcvADSzUSnvizfP9bUGs8vAYPS37NdRLQ1qxuErxx0cZlag4QqqPEPKweHgMLNRIq+Q8rbqZmajRKtPariwt2Y0M7MLjoPDzMwycXCYmVkmDg4zM8vEwWFmZpmMitNxJR0B/jPID58KHM2xnAtJO48N2nt8HtvINZLGd3lETDu7c1QEx1BI2tLfecztoJ3HBu09Po9t5GqH8XmpyszMMnFwmJlZJg6Oc1tZdAEt1M5jg/Yen8c2co348fkYh5mZZeIZh5mZZeLgMDOzTBwcr0DS9ZKekvS0pNuKricvki6T9BdJuyXtkrS86JryJqksabuk+4uuJW+SJktaL+lJSXskXV10TXmR9MX0Z3KnpHWSzn3D8guYpFWSDkva2dR3saSHJP0rfZ5SZI2D4eAYgKQycAfwHmAecJOkecVWlZsa8OWImAcsAj7fRmPrsxzYU3QRLfIT4M8R8UZgAW0yTkkzgVuBhRExn+SW0zcWW9WQ/Qq4/qy+24BNETEX2JS+HlEcHAO7Cng6IvZGRA9wN7Ck4JpyERGdEbEtbb9I8otnZrFV5UfSLOB9wJ1F15I3SZOAdwJ3AURET0QcK7aqXFWAcZIqwHjg2YLrGZKI+Bvw3FndS4A1aXsNsHRYi8qBg2NgM4H9Ta8P0Ea/XPtImg1cCTxabCW5+jHwNaBxrjeOQHOAI8DqdCnuTkkTii4qDxFxEPgh8AzQCTwfEQ8WW1VLTI+IzrR9CJheZDGD4eAYxSRNBH4PfCEiXii6njxIej9wOCK2Fl1Li1SAtwI/j4grgeOMwKWO/qRr/UtIwvFSYIKkjxdbVWtFcj3EiLsmwsExsIPAZU2vZ6V9bUFSlSQ01kbEvUXXk6NrgA9K2keyvLhY0m+KLSlXB4ADEdE3Q1xPEiTt4Drg3xFxJCJ6gXuBtxdcUyv8V9IMgPT5cMH1ZObgGNhjwFxJcySNITlIt6HgmnIhSSRr5Hsi4kdF15OniPhGRMyKiNkk37PNEdE2f7VGxCFgv6Q3pF3XArsLLClPzwCLJI1Pf0avpU0O/J9lA3Bz2r4Z+GOBtQxKpegCLlQRUZN0C7CR5OyOVRGxq+Cy8nIN8AngCUk70r5vRsQDBdZk528ZsDb9g2Yv8KmC68lFRDwqaT2wjeTMv+2M8O05JK0D3gVMlXQA+DbwA+B3kj5NcruHjxRX4eB4yxEzM8vES1VmZpaJg8PMzDJxcJiZWSYODjMzy8TBYWZmmTg4zHIgqS5pR9Mjt6u5Jc1u3l3VrGi+jsMsHyci4i1FF2E2HDzjMGshSfsk3S7pCUn/kPS6tH+2pM2SHpe0SdJr0v7pku6T9M/00bflRlnSL9N7VTwoaVxhg7JRz8Fhlo9xZy1V3dD0b89HxJuAn5Hs3AvwU2BNRLwZWAusSPtXAH+NiAUke1D17VYwF7gjIq4AjgEfavF4zAbkK8fNciDppYiY2E//PmBxROxNN5Y8FBGvknQUmBERvWl/Z0RMlXQEmBUR3U2fYzbwUHrjHyR9HahGxPdbPzKzl/OMw6z1YoB2Ft1N7To+PmkFcnCYtd4NTc9/T9uPcPq2qB8DHk7bm4DPwan7pk8ariLNzpf/ajHLx7imnYYhuSd43ym5UyQ9TjJruCntW0ZyF7+vktzRr2+H2+XAynTn1DpJiHRidgHxMQ6zFkqPcSyMiKNF12KWFy9VmZlZJp5xmJlZJp5xmJlZJg4OMzPLxMFhZmaZODjMzCwTB4eZmWXyf7HtU8ICSJ/hAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUN8puFoEZtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1920b6c-3ba5-43d4-e76c-3777575ede70"
      },
      "source": [
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for i in range(N):\n",
        "        z=np.dot(w,X[i])+b\n",
        "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
        "            predict.append(1)\n",
        "        else:\n",
        "            predict.append(0)\n",
        "    return np.array(predict)\n",
        "print(1-np.sum(y_train - pred(w,b,x_train))/len(x_train))\n",
        "print(1-np.sum(y_test  - pred(w,b,x_test))/len(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.94952\n",
            "0.94696\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}